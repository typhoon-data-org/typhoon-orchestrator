{% import 'adapter.j2' as adapter %}
# DAG name: {{ name }}
# Schedule interval = {{ schedule_interval }}
import os
from datetime import datetime

import dateutil.parser
import typhoon.contrib.functions as typhoon_functions
import typhoon.contrib.transformations as typhoon_transformations
from typhoon.contrib.hooks.hook_factory import get_hook
from typhoon.variables import get_variable_contents
from typhoon.handler import handle
from typhoon.core import SKIP_BATCH, task
from typhoon.models.dag import dag
from typhoon.models.task import task_logging_wrapper
{% for transformations_module in get_transformations_modules(edges) %}
import {{ transformations_module }}
{% endfor %}
{% for functions_module in get_functions_modules(nodes) %}
import {{ functions_module }}
{% endfor %}

os.environ['TYPHOON_HOME'] = os.path.dirname(__file__)
DAG_CONFIG = {}     # Global variable with DAG config. Will be populated in main

{% if debug_mode %}

# Only meant for local debugging. Do NOT use in production
os.environ['TYPHOON-ENV'] = '{{ environment }}'

{% endif %}

@dag
def {{ name }}_main(event, context):
    if event.get('type'):     # Async execution
        return handle(event, context)

    # Main execution
    DAG_CONFIG['dag_id'] = '{{ name }}'
    DAG_CONFIG['execution_date'] = dateutil.parser.parse(event['time'])
    DAG_CONFIG['ds'] = event['time'].split('T')[0]
    DAG_CONFIG['ds_nodash'] = event['time'].replace('-', '')
    DAG_CONFIG['ts'] = event['time'].replace('Z', '')
    DAG_CONFIG['etl_timestamp'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')

    {% for source in get_sources(structure) %}
    {{ source }}_branches()
    {% endfor %}


# Branches
{% for node_name, node in nodes.items() %}
@task(asynchronous={% if not dev_mode and node.get('async', True) %}True{% else %}False{% endif %}, dag_name='{{ name }}', execution_context=DAG_CONFIG)
def {{ node_name }}_branches({% if node_name not in get_sources(structure)%}data, {% endif %}batch_num=0):
    data_generator = {{ node_name }}_node({% if node_name not in get_sources(structure)%}data, {% endif %}batch_num)
    for batch_num, data in enumerate(data_generator or [], start=1):
        if data is SKIP_BATCH:
            print(f'Skipping batch {batch_num} for {{ node_name }}')
            continue

        {% for out_node in structure[node_name] %}
        config = {}
        {% for k, v in get_edge(edges, node_name, out_node)[1]['adapter'].items() %}
        {{ adapter.adapter_params(k, v) | indent(8, False) }}
        {% endfor %}
        {{ out_node }}_branches(config, batch_num)

        {% else %}
        pass        # Necessary for the generator to be exhausted since it probably has side effects

        {% endfor %}

{% endfor %}
# Nodes
{% for node_name, node in nodes.items() %}
def {{ node_name }}_node({% if node_name not in get_sources(structure)%}config, {% endif %}batch_num):
    node_function = task_logging_wrapper(
        dag_config=DAG_CONFIG,
        task_id='{{ node_name }}',
        batch_num=batch_num,
    )({{ node['function'] | clean_function_name('functions') }})       # Wrapper to add logging

    {% if node_name in get_sources(structure)%}
    config = {}

    {% endif %}
    {% for k, v in node.get('config', {}).items() %}
    {{ adapter.adapter_params(k, v) | indent(4, False) }}
    {% endfor %}
    yield from node_function(
        **config,
    )

{% endfor %}
{% if debug_mode %}
if __name__ == '__main__':
    example_event = {
        'time': '2019-02-05T03:00:00Z'
    }
    {{ name }}_main(example_event, None)
{% endif %}
