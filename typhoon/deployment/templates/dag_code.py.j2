# DAG name: {{ name }}
# Schedule interval = {{ schedule_interval }}
import io
import logging
from datetime import datetime

import dateutil.parser
from typhoon.aws import write_logs
from typhoon.models.dag import dag
from zappa.async import task

{% for functions_module in get_functions_modules(nodes) %}
from functions import {{ functions_module }}
{% endfor %}
{% for adapter_module in get_adapters_modules(adapters) %}
from adapters import {{ adapter_module }}
{% endfor %}


DAG_CONFIG = {} # Global variable with DAG config. Will be populated in main


@dag
def {{ name }}_main(event, context):
    DAG_CONFIG['dag_id'] = '{{ name }}'
    DAG_CONFIG['execution_date'] = dateutil.parser.parse(event['time'])
    DAG_CONFIG['ds'] = event['time'].split()[0]
    DAG_CONFIG['ds_nodash'] = event['time'].replace('-', '')
    DAG_CONFIG['etl_timestamp'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')

    {% for source in get_sources(structure) %}
    {{ source }}_branch()
    {% endfor %}


# Branches
{% for node_name, node in nodes.items() %}
@task
def {{ node_name }}_branch({% if node_name not in get_sources(structure)%}data, {% endif %}batch_num=0):
    data_generator = {{ node_name }}_node({% if node_name not in get_sources(structure)%}data, {% endif %}batch_num)
    for batch_num, data in enumerate(data_generator, start=1):
        {% for out_node in structure[node_name] %}
        data = {{ get_edge(edges, node_name, out_node)[1]['adapter'] }}_adapter(data)
        {{ out_node }}_branch(data, batch_num)
        {% else %}
        pass        # Necessary for the generator to be exhausted since it probably has side effects
        {% endfor %}


{% endfor %}
# Adapters
{% for adapter_name, adapter in adapters.items() %}
def {{ adapter_name }}_adapter(data):
    return {{ adapter['function'] }}(
        data=data,
        {% for param, value in adapter.get('config', {}).items() %}
        {{ param }}={{ "'" + value + "'" if value is string else value }},
        {% endfor %}
    )


{% endfor %}
# Nodes
{% for node_name, node in nodes.items() %}
def {{ node_name }}_node({% if node_name not in get_sources(structure)%}data, {% endif %}batch_num):
    log_buffer = io.StringIO()
    try:
        root = logging.getLogger()
        handler = logging.StreamHandler()   # Log to stdout
        root.addHandler(handler)
        handler = logging.StreamHandler(log_buffer)
        root.addHandler(handler)
        root.setLevel(logging.INFO)

        yield from {{ node['function'] }}(
            {% for param, value in node.get('config', {}).items() %}
            {{ param }}={{ "'" + value + "'" if value is string else value }},
            {% endfor %}
            {% if node_name not in get_sources(structure) %}
            **data,
            {% endif %}
        )
    except Exception as e:
        logging.error(e)
    finally:
        dag_id = DAG_CONFIG['dag_id']
        ds = DAG_CONFIG['ds']
        etl_timestamp = DAG_CONFIG['etl_timestamp']
        write_logs(
            log_buffer.getvalue(),
            bucket='typhoon-orchestrator',
            key=f'logs/{dag_id}/{ds}/execution{etl_timestamp}/{{ node_name }}_{batch_num}.log'
        )


{% endfor %}
if __name__ == '__main__':
    example_event = {
        'time': '2019-02-05T16:52:09Z'
    }
    {{ name }}_main(example_event, None)
